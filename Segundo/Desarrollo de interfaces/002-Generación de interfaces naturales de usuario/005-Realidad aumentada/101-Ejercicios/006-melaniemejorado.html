<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <title>MediaPipe FaceMesh · Face PNG Overlay (fixed mirror/projection)</title>
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <style>
    html, body { margin:0; background:#111; color:#eee; font-family:system-ui,-apple-system,Segoe UI,Roboto,sans-serif; }
    .wrap { position:relative; display:grid; place-items:center; min-height:100vh; }
    video, canvas { max-width: min(96vw, 960px); width:100%; height:auto; border-radius:12px; }
    video { display:none; } /* we paint the video onto the canvas */
    .hud {
      position: fixed; left: 50%; transform: translateX(-50%);
      bottom: 16px; display:flex; gap:10px; align-items:center; flex-wrap:wrap;
      background: rgba(0,0,0,.55); color:#fff; padding:10px 12px; border-radius: 12px; backdrop-filter: blur(6px);
      font-size: 14px;
    }
    .hud label { display:flex; align-items:center; gap:8px; }
    .badge { position: fixed; top: 12px; left: 12px; background: rgba(0,0,0,.55); padding:6px 10px; border-radius:999px; font-size:12px; }
    .file { padding:4px 8px; background:#222; border-radius:8px; }
    select, input[type="range"] { accent-color:#ff2a88; }
  </style>

  <!-- MediaPipe legacy UMD JS (globals) -->
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/face_mesh.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/drawing_utils/drawing_utils.js"></script>
  <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js"></script>
</head>
<body>
  <div class="wrap">
    <div class="badge">FaceMesh · Face PNG Overlay</div>
    <video id="input_video" autoplay playsinline muted></video>
    <canvas id="output_canvas" width="640" height="480"></canvas>

    <div class="hud">
      <label class="file">PNG: <input id="pngfile" type="file" accept="image/png" /></label>
      <label>
        Smooth: <input id="smooth" type="range" min="0" max="1" step="0.1" value="0.5" />
      </label>
      <label>
        Mirror: <input id="mirror" type="checkbox" checked />
      </label>
      <label>
        Blend:
        <select id="blend">
          <option>source-over</option>
          <option selected>soft-light</option>
          <option>overlay</option>
          <option>multiply</option>
          <option>screen</option>
          <option>lighten</option>
          <option>darken</option>
        </select>
      </label>
      <label>
        Alpha: <input id="pngAlpha" type="range" min="0" max="1" step="0.02" value="0.9" />
      </label>
      <label>
        Scale: <input id="scale" type="range" min="0.5" max="2" step="0.01" value="1.2" />
      </label>
      <label>
        Rotate°: <input id="rot" type="range" min="-40" max="40" step="1" value="0" />
      </label>
      <label>
        Off X: <input id="offx" type="range" min="-200" max="200" step="1" value="0" />
      </label>
      <label>
        Off Y: <input id="offy" type="range" min="-200" max="200" step="1" value="10" />
      </label>
    </div>
  </div>

  <script>
    // ---- DOM ----
    const video  = document.getElementById('input_video');
    const canvas = document.getElementById('output_canvas');
    const ctx    = canvas.getContext('2d');
    const ui = {
      file:     document.getElementById('pngfile'),
      smooth:   document.getElementById('smooth'),
      mirror:   document.getElementById('mirror'),
      blend:    document.getElementById('blend'),
      pngAlpha: document.getElementById('pngAlpha'),
      scale:    document.getElementById('scale'),
      rot:      document.getElementById('rot'),
      offx:     document.getElementById('offx'),
      offy:     document.getElementById('offy'),
    };

    // ---- Smoothing ----
    let prevLandmarks = null;
    const lerp = (a,b,t)=>a+(b-a)*t;
    function smoothLandmarks(curr, t){
      if (!prevLandmarks || prevLandmarks.length !== curr.length) {
        prevLandmarks = curr.map(p=>({...p}));
        return curr;
      }
      const sm = curr.map((p,i)=>({
        x: lerp(prevLandmarks[i].x, p.x, t),
        y: lerp(prevLandmarks[i].y, p.y, t),
        z: lerp(prevLandmarks[i].z ?? 0, p.z ?? 0, t),
      }));
      prevLandmarks = sm.map(p=>({...p}));
      return sm;
    }

    // ---- Landmark index sets ----
    const FACE_OVAL = [10,338,297,332,284,251,389,356,454,323,361,288,397,365,379,378,400,377,152,148,176,149,150,136,172,58,132,93,234,127,162,21,54,103,67,109];

    // ---- Drawing helpers ----
    function drawVideoFrame(img, mirror){
      ctx.save();
      ctx.clearRect(0,0,canvas.width,canvas.height);
      if (mirror) {
        ctx.translate(canvas.width, 0);
        ctx.scale(-1, 1);
      }
      ctx.drawImage(img, 0, 0, canvas.width, canvas.height);
      ctx.restore();
    }

    function toPx(p, mirror){
      const x = (mirror ? (1 - p.x) : p.x) * canvas.width; // mirror-aware X
      const y = p.y * canvas.height;
      return { x, y };
    }

    function pathPolygonFromIndices(landmarks, indices, mirror){
      ctx.beginPath();
      indices.forEach((idx,i)=>{
        const p = toPx(landmarks[idx], mirror);
        if (i===0) ctx.moveTo(p.x,p.y); else ctx.lineTo(p.x,p.y);
      });
      ctx.closePath();
    }

    // ---- Face PNG state ----
    let faceImg = null;
    ui.file.addEventListener('change', (e)=>{
      const file = e.target.files?.[0];
      if (!file) return;
      const url = URL.createObjectURL(file);
      const img = new Image();
      img.onload = ()=>{ faceImg = img; URL.revokeObjectURL(url); };
      img.src = url;
    });

    // ---- Overlay drawing (fixed mirror/projection) ----
    function drawFacePNG(landmarks, mirror){
      if (!faceImg) return;

      // Key points (MediaPipe indices)
      const L = landmarks[33];   // left eye outer (subject's left)
      const R = landmarks[263];  // right eye outer
      const N = landmarks[1];    // nose tip
      const M = landmarks[13];   // mouth center

      // Convert to pixels (mirror-aware)
      const pL = toPx(L, mirror), pR = toPx(R, mirror), pN = toPx(N, mirror), pM = toPx(M, mirror);

      // Rotation from eye line (computed AFTER mirroring => correct sign)
      const eyeDx = pR.x - pL.x;
      const eyeDy = pR.y - pL.y;
      const angle = Math.atan2(eyeDy, eyeDx);

      // Scale from face height (forehead to chin)
      const chin = toPx(landmarks[152], mirror);
      const forehead = toPx(landmarks[10], mirror);
      const faceH = Math.hypot(chin.x-forehead.x, chin.y-forehead.y);

      const userScale = parseFloat(ui.scale.value || '1');
      const imgW = faceImg.width, imgH = faceImg.height;
      const targetH = faceH * 1.05 * userScale;
      const scale = targetH / imgH;
      const drawW = imgW * scale;
      const drawH = imgH * scale;

      // Anchor: weighted mix (eyes, nose, mouth)
      const midEyes = { x: (pL.x+pR.x)/2, y:(pL.y+pR.y)/2 };
      const anchor  = {
        x: (midEyes.x*0.5 + pN.x*0.3 + pM.x*0.2),
        y: (midEyes.y*0.5 + pN.y*0.35 + pM.y*0.15),
      };

      // User controls
      const offx = parseFloat(ui.offx.value||'0');
      const offy = parseFloat(ui.offy.value||'0');
      const rot  = (parseFloat(ui.rot.value||'0') * Math.PI) / 180;

      // Clip to face oval (mirror-aware)
      ctx.save();
      pathPolygonFromIndices(landmarks, FACE_OVAL, mirror);
      ctx.clip();

      // Blend + alpha
      ctx.globalCompositeOperation = ui.blend.value || 'source-over';
      ctx.globalAlpha = parseFloat(ui.pngAlpha.value||'0.9');

      // Transform: translate to anchor, rotate, tiny yaw skew from z-depths
      ctx.translate(anchor.x, anchor.y);
      ctx.rotate(angle + rot);

      // Subtle 2.5D: yaw skew sign corrected for mirror
      const yawSign = mirror ? -1 : 1;
      const zL = L.z ?? 0, zR = R.z ?? 0;
      const yawSkew = yawSign * Math.max(-0.2, Math.min(0.2, (zL - zR)));
      ctx.transform(1, 0, yawSkew, 1, 0, 0);

      // Draw centered (slightly up toward forehead)
      ctx.drawImage(faceImg, -drawW/2 + offx, -drawH*0.45 + offy, drawW, drawH);

      // Restore
      ctx.restore();
      ctx.globalCompositeOperation = 'source-over';
      ctx.globalAlpha = 1;
    }

    // ---- FaceMesh setup ----
    const FaceMeshCtor = (window.FaceMesh && window.FaceMesh.FaceMesh) || window.FaceMesh;
    const faceMesh = new FaceMeshCtor({
      locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/face_mesh/${file}`
    });
    faceMesh.setOptions({
      maxNumFaces: 1,
      refineLandmarks: true,
      minDetectionConfidence: 0.6,
      minTrackingConfidence: 0.5
    });

    faceMesh.onResults((results)=>{
      const mirror = ui.mirror.checked;

      // Background video (mirrored visually if requested)
      drawVideoFrame(results.image, mirror);

      const faces = results.multiFaceLandmarks;
      if (!faces || !faces.length) return;

      const t = parseFloat(ui.smooth.value || '0.5');
      const lm = smoothLandmarks(faces[0], t);

      // Draw the PNG overlay with mirror-aware projection
      drawFacePNG(lm, mirror);
    });

    // ---- Camera ----
    const camera = new Camera(video, {
      onFrame: async () => { await faceMesh.send({ image: video }); },
      width:  640,
      height: 480
    });
    camera.start().catch(err=>{
      console.error(err);
      alert('Camera error. Use https or localhost and allow camera permissions.');
    });
  </script>
</body>
</html>

