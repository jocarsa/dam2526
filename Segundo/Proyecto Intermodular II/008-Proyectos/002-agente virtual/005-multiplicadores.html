<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<title>Avatar follows your face – Three.js + MediaPipe</title>
<meta name="viewport" content="width=device-width,initial-scale=1" />
<link rel="icon" href="data:,">

<!-- Import map to resolve the bare specifier "three" used by GLTFLoader -->
<script type="importmap">
{
  "imports": {
    "three": "https://cdn.jsdelivr.net/npm/three@0.160/build/three.module.js",
    "three/addons/": "https://cdn.jsdelivr.net/npm/three@0.160/examples/jsm/"
  }
}
</script>

<style>
  html, body { margin:0; height:100%; overflow:hidden; background:#0e0f13; color:#e9eef3; font-family:system-ui, Segoe UI, Roboto, Ubuntu, Cantarell; }
  #stage { position:fixed; inset:0; }
  :root { --preview-w:260px; --preview-h:195px; }
  .preview {
    position:fixed; right:16px; bottom:16px; width:var(--preview-w); height:var(--preview-h);
    border-radius:12px; overflow:hidden; box-shadow:0 8px 24px rgba(0,0,0,.45);
    border:1px solid rgba(255,255,255,.08); background:#14161d; z-index:10;
  }
  .preview video, .preview canvas { position:absolute; width:100%; height:100%; object-fit:cover; }
  .preview video { transform:scaleX(-1); }
  .header { position:absolute; inset:0 0 auto 0; height:28px; background:linear-gradient(180deg, rgba(0,0,0,.55), transparent);
    font-size:12px; display:flex; align-items:center; gap:8px; padding:0 10px; color:#c9d2db; }
  .dot { width:8px; height:8px; border-radius:50%; background:#e74c3c; box-shadow:0 0 10px rgba(231,76,60,.8); }
</style>
</head>
<body>
  <div id="stage"></div>

  <div class="preview">
    <div class="header"><span class="dot" id="camDot"></span> Webcam</div>
    <video id="vid" autoplay playsinline muted></video>
    <canvas id="overlay" width="640" height="480" style="display:none"></canvas>
  </div>

  <script type="module">
    import * as THREE from "three";
    import { GLTFLoader } from "three/addons/loaders/GLTFLoader.js";
    import { FaceDetector, FilesetResolver } from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

    /* ---------- THREE.JS ---------- */
    const container = document.getElementById("stage");
    const renderer  = new THREE.WebGLRenderer({ antialias:true });
    renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
    renderer.setSize(window.innerWidth, window.innerHeight);
    renderer.outputColorSpace = THREE.SRGBColorSpace;
    renderer.toneMapping = THREE.ACESFilmicToneMapping;
    renderer.shadowMap.enabled = true;
    container.appendChild(renderer.domElement);

    const scene = new THREE.Scene();
    scene.background = new THREE.Color(0x0e0f13);

    // You set this narrower FOV; keep it
    const camera = new THREE.PerspectiveCamera(10, window.innerWidth/window.innerHeight, 0.1, 100);
    camera.position.set(0, 1.3, 3);

    // Soft lights
    scene.add(new THREE.HemisphereLight(0xffffff, 0x334455, 0.6));
    const dir = new THREE.DirectionalLight(0xffffff, 1);
    dir.position.set(3,5,5);
    dir.castShadow = true;
    scene.add(dir);

    // Ground (soft shadow feel)
    const ground = new THREE.Mesh(
      new THREE.PlaneGeometry(20,20),
      new THREE.MeshStandardMaterial({ color:0x0f1116, roughness:0.95, metalness:0 })
    );
    ground.rotation.x = -Math.PI/2;
    ground.receiveShadow = true;
    scene.add(ground);

    // Avatar group we rotate
    const avatarRoot = new THREE.Group();
    avatarRoot.position.set(0, 1.0, 0);
    scene.add(avatarRoot);

    // Load avatar.glb from same folder
    let avatar;
    const loader = new GLTFLoader();
    loader.load("./avatar.glb", (gltf)=>{
      avatar = gltf.scene;
      avatar.traverse(o=>{ if(o.isMesh){ o.castShadow = true; o.receiveShadow = true; }});
      // Face camera (adjust/remove if already correct)
      avatar.rotation.y = Math.PI;

      // Normalize scale & center
      const box = new THREE.Box3().setFromObject(avatar);
      const size = new THREE.Vector3(); box.getSize(size);
      const scale = 1.2 / Math.max(size.x, size.y, size.z);
      avatar.scale.setScalar(scale);
      const center = new THREE.Vector3(); box.getCenter(center);
      avatar.position.sub(center.multiplyScalar(scale));

      avatarRoot.add(avatar);
    });

    window.addEventListener("resize", ()=>{
      camera.aspect = window.innerWidth / window.innerHeight;
      camera.updateProjectionMatrix();
      renderer.setSize(window.innerWidth, window.innerHeight);
    });

    /* ---------- MEDIAPIPE ---------- */
    const video   = document.getElementById("vid");
    const overlay = document.getElementById("overlay");
    const octx    = overlay.getContext("2d");
    const camDot  = document.getElementById("camDot");

    let showBBox = false;
    window.addEventListener("keydown", (e)=>{
      if (e.key.toLowerCase() === "b") {
        showBBox = !showBBox;
        overlay.style.display = showBBox ? "block" : "none";
      }
    });

    const smoother = (alpha=0.18)=>{
      let sx=null, sy=null;
      return (x,y)=>{ if(sx==null){sx=x; sy=y;} sx += alpha*(x-sx); sy += alpha*(y-sy); return [sx,sy]; };
    };
    const smoothXY = smoother(0.18);

    async function setupCam(){
      const stream = await navigator.mediaDevices.getUserMedia({ video: { width:640, height:480 } });
      video.srcObject = stream;
      await video.play();
    }

    const vision = await FilesetResolver.forVisionTasks(
      "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"
    );
    const detector = await FaceDetector.createFromOptions(vision, {
      baseOptions: {
        modelAssetPath: "https://storage.googleapis.com/mediapipe-models/face_detector/blaze_face_short_range/float16/1/blaze_face_short_range.tflite"
      },
      runningMode: "VIDEO",
      minDetectionConfidence: 0.5
    });

    await setupCam();

    function drawBox(bb){
      const W = overlay.width = 640, H = overlay.height = 480;
      octx.clearRect(0,0,W,H);
      const x = W - (bb.originX + bb.width); // mirrored preview
      const y = bb.originY;
      octx.strokeStyle = "rgba(0,200,255,0.9)";
      octx.lineWidth = 2;
      octx.strokeRect(x,y,bb.width,bb.height);
    }

    /* ---------- ROTATION MAPPING WITH MULTIPLIERS ---------- */
    const yawMax   = THREE.MathUtils.degToRad(20); // base range for left-right (Y)
    const pitchMax = THREE.MathUtils.degToRad(12); // base range for up-down (X)

    // Sensitivity & inversion controls
    const yawMultiplier   = 3; // >1 = more sensitive, <1 = less
    const pitchMultiplier = 3; // >1 = more sensitive, <1 = less
    const invertYaw       = 1;   // set to -1 to invert horizontal
    const invertPitch     = 1;   // set to -1 to invert vertical

    const clamp = (v,min,max)=> Math.max(min, Math.min(max, v));
    const current = { x:0, y:0 };
    const lerp = (a,b,t)=> a + (b - a) * t;

    function animate(){
      requestAnimationFrame(animate);
      renderer.render(scene, camera);
      avatarRoot.rotation.x = lerp(avatarRoot.rotation.x, current.x, 0.15);
      avatarRoot.rotation.y = lerp(avatarRoot.rotation.y, current.y, 0.15);
    }
    animate();

    function tick(){
      const now = performance.now();
      const res = detector.detectForVideo(video, now);
      if (res?.detections?.length) {
        const best = res.detections.reduce((a,b)=>(a.categories?.[0]?.score||0)>=(b.categories?.[0]?.score||0)?a:b);
        const bb = best.boundingBox;

        // Face center normalized 0..1
        const cx = (bb.originX + bb.width*0.5) / video.videoWidth;
        const cy = (bb.originY + bb.height*0.5) / video.videoHeight;

        // Mirror X to match selfie preview
        const mx = 1 - cx, my = cy;
        const [sx, sy] = smoothXY(mx, my);

        const dx = sx - 0.5; // -0.5..+0.5
        const dy = sy - 0.5;

        // Apply multipliers and inversion (pitch already fixed: move head up → avatar pitches up)
        current.y = clamp(invertYaw   * dx * 2 * yawMax   * yawMultiplier,   -yawMax,   yawMax);   // yaw (Y)
        current.x = clamp(invertPitch * dy * 2 * pitchMax * pitchMultiplier, -pitchMax, pitchMax); // pitch (X)

        camDot.style.background = "#2ecc71";
        camDot.style.boxShadow  = "0 0 10px rgba(46,204,113,.9)";
        if (showBBox) drawBox(bb); else octx.clearRect(0,0,overlay.width,overlay.height);
      } else {
        // ease back to neutral
        current.x = lerp(current.x, 0, 0.05);
        current.y = lerp(current.y, 0, 0.05);
        camDot.style.background = "#e74c3c";
        camDot.style.boxShadow  = "0 0 10px rgba(231,76,60,.8)";
        octx.clearRect(0,0,overlay.width,overlay.height);
      }
      requestAnimationFrame(tick);
    }
    requestAnimationFrame(tick);
  </script>
</body>
</html>

