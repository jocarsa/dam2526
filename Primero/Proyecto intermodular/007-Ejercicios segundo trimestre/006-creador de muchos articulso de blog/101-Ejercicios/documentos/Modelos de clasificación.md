---
slug: modelos-de-clasificacion
title: Modelos de clasificación (comoprogramar.es)
description: Aprende a diseñar, entrenar y evaluar modelos de clasificación en machine learning. Comprende cómo funcionan los principales algoritmos, cómo interpretar sus resultados y cómo usarlos de forma responsable en problemas reales.
keywords:
  - modelos de clasificación
  - machine learning clasificación
  - clasificación binaria
  - clasificación multiclase
  - algoritmos de clasificación
  - modelos predictivos
level: Intermedio
duration_estimate: "35-50 horas"
prerequisites:
  - "Machine Learning desde cero"
  - "Aprendizaje supervisado"
  - "Probabilidad y estadística para IA (recomendado)"
audience:
  - "Estudiantes de ciencia de datos"
  - "Científicos de datos en formación"
  - "Ingenieros de IA"
  - "Desarrolladores"
updated: 2025-12-26
---

# Modelos de clasificación

## Objetivos del curso

## Cómo usar este curso

## Clasificar no es solo “predecir una etiqueta”

---

# Unidad 1 — Qué es un problema de clasificación

## 1.1 — Tomar decisiones a partir de datos

### Lección 1.1.1 — Clasificación como decisión
### Lección 1.1.2 — Diferencia entre regresión y clasificación
### Lección 1.1.3 — Casos reales de clasificación

## 1.2 — Tipos de problemas de clasificación

### Lección 1.2.1 — Clasificación binaria
### Lección 1.2.2 — Clasificación multiclase
### Lección 1.2.3 — Clasificación multietiqueta

---

# Unidad 2 — Datos y etiquetas para clasificación

## 2.1 — Qué son las etiquetas

### Lección 2.1.1 — Clases y categorías
### Lección 2.1.2 — Etiquetas ruidosas
### Lección 2.1.3 — Ambigüedad en clases

## 2.2 — Distribución de clases

### Lección 2.2.1 — Clases balanceadas
### Lección 2.2.2 — Desbalance de clases
### Lección 2.2.3 — Impacto en modelos

---

# Unidad 3 — Clasificadores lineales

## 3.1 — Regresión logística

### Lección 3.1.1 — Intuición probabilística
### Lección 3.1.2 — Función sigmoide
### Lección 3.1.3 — Interpretación de coeficientes

## 3.2 — Clasificadores lineales multiclase

### Lección 3.2.1 — One-vs-Rest
### Lección 3.2.2 — Softmax (visión conceptual)
### Lección 3.2.3 — Limitaciones de linealidad

---

# Unidad 4 — Clasificación basada en distancia

## 4.1 — k-Nearest Neighbors (k-NN)

### Lección 4.1.1 — Similitud y distancia
### Lección 4.1.2 — Elección de k
### Lección 4.1.3 — Coste computacional

## 4.2 — Métricas de distancia

### Lección 4.2.1 — Euclídea
### Lección 4.2.2 — Manhattan
### Lección 4.2.3 — Impacto del escalado

---

# Unidad 5 — Modelos basados en árboles

## 5.1 — Árboles de decisión

### Lección 5.1.1 — División del espacio
### Lección 5.1.2 — Criterios de impureza
### Lección 5.1.3 — Interpretabilidad

## 5.2 — Ensembles de árboles

### Lección 5.2.1 — Random Forest
### Lección 5.2.2 — Gradient Boosting
### Lección 5.2.3 — Potencia y riesgos

---

# Unidad 6 — Support Vector Machines (SVM)

## 6.1 — Clasificación con márgenes

### Lección 6.1.1 — Hiperplanos
### Lección 6.1.2 — Márgen máximo
### Lección 6.1.3 — Robustez

## 6.2 — Kernels en clasificación

### Lección 6.2.1 — Separación no lineal
### Lección 6.2.2 — Kernels comunes
### Lección 6.2.3 — Coste y escalabilidad

---

# Unidad 7 — Evaluación de modelos de clasificación

## 7.1 — Métricas fundamentales

### Lección 7.1.1 — Accuracy
### Lección 7.1.2 — Precision
### Lección 7.1.3 — Recall y F1

## 7.2 — Matriz de confusión

### Lección 7.2.1 — Falsos positivos y negativos
### Lección 7.2.2 — Interpretación por clase
### Lección 7.2.3 — Impacto en decisiones reales

---

# Unidad 8 — Clasificación con datos desbalanceados

## 8.1 — El problema del desbalance

### Lección 8.1.1 — Por qué accuracy falla
### Lección 8.1.2 — Riesgos en producción
### Lección 8.1.3 — Casos reales

## 8.2 — Estrategias de mitigación

### Lección 8.2.1 — Reponderación de clases
### Lección 8.2.2 — Oversampling y undersampling
### Lección 8.2.3 — Ajuste de umbrales

---

# Unidad 9 — Umbrales, probabilidades y decisiones

## 9.1 — Scores vs probabilidades

### Lección 9.1.1 — Qué devuelve un clasificador
### Lección 9.1.2 — Calibración
### Lección 9.1.3 — Confianza aparente

## 9.2 — Elección del umbral de decisión

### Lección 9.2.1 — Coste de errores
### Lección 9.2.2 — Curvas ROC
### Lección 9.2.3 — AUC

---

# Unidad 10 — Interpretabilidad y explicabilidad

## 10.1 — Entender por qué clasifica así

### Lección 10.1.1 — Importancia de variables
### Lección 10.1.2 — Árboles vs modelos complejos
### Lección 10.1.3 — Límites de explicación

## 10.2 — Riesgos éticos en clasificación

### Lección 10.2.1 — Discriminación automática
### Lección 10.2.2 — Sesgos en clases
### Lección 10.2.3 — Uso responsable

---

# Unidad 11 — Clasificación en producción

## 11.1 — Uso real de clasificadores

### Lección 11.1.1 — Clasificación batch
### Lección 11.1.2 — Clasificación en tiempo real
### Lección 11.1.3 — Latencia y costes

## 11.2 — Mantenimiento del clasificador

### Lección 11.2.1 — Drift de datos
### Lección 11.2.2 — Reentrenamiento
### Lección 11.2.3 — Monitorización de errores

---

# Unidad 12 — Mini-proyecto de clasificación

## 12.1 — Proyecto guiado completo

### Lección 12.1.1 — Definición del problema
### Lección 12.1.2 — Preparación de datos
### Lección 12.1.3 — Entrenamiento de varios clasificadores
### Lección 12.1.4 — Evaluación comparativa
### Lección 12.1.5 — Selección final y conclusiones

---

# Unidad 13 — Siguientes pasos

## 13.1 — Qué aprender después

### Lección 13.1.1 — Modelos de regresión
### Lección 13.1.2 — Deep Learning para clasificación
### Lección 13.1.3 — IA aplicada a decisiones reales

## 13.2 — Ruta recomendada en comoprogramar.es

### Lección 13.2.1 — Aprendizaje supervisado
### Lección 13.2.2 — Machine Learning clásico
### Lección 13.2.3 — Deep Learning desde cero

---

## Recursos recomendados

## Glosario (opcional)

## Créditos

> Última actualización: **2025-12-26**

