---
slug: overfitting-y-underfitting
title: Overfitting y underfitting (comoprogramar.es)
description: Aprende a identificar, entender y corregir el overfitting y el underfitting en modelos de machine learning. Domina el equilibrio entre complejidad y generalización para construir modelos fiables y útiles.
keywords:
  - overfitting
  - underfitting
  - sesgo y varianza
  - generalización
  - evaluación de modelos
  - machine learning práctico
level: Intermedio
duration_estimate: "20-30 horas"
prerequisites:
  - "Machine Learning desde cero"
  - "Evaluación y validación de modelos (recomendado)"
audience:
  - "Estudiantes de ciencia de datos"
  - "Científicos de datos en formación"
  - "Ingenieros de IA"
  - "Desarrolladores"
updated: 2025-12-26
---

# Overfitting y underfitting

## Objetivos del curso

## Cómo usar este curso

## Aprender demasiado y aprender demasiado poco

---

# Unidad 1 — Qué significan realmente overfitting y underfitting

## 1.1 — Aprender patrones vs memorizar datos

### Lección 1.1.1 — Qué es generalizar
### Lección 1.1.2 — Aprender la señal
### Lección 1.1.3 — Aprender el ruido

## 1.2 — Definiciones operativas

### Lección 1.2.1 — Qué es underfitting
### Lección 1.2.2 — Qué es overfitting
### Lección 1.2.3 — Por qué ambos son problemas graves

---

# Unidad 2 — El compromiso bias–variance

## 2.1 — Sesgo (bias)

### Lección 2.1.1 — Modelos demasiado simples
### Lección 2.1.2 — Señales de alto sesgo
### Lección 2.1.3 — Ejemplos prácticos

## 2.2 — Varianza

### Lección 2.2.1 — Modelos demasiado complejos
### Lección 2.2.2 — Sensibilidad a los datos
### Lección 2.2.3 — Ejemplos prácticos

---

# Unidad 3 — Diagnóstico con datos de entrenamiento y prueba

## 3.1 — Comparar errores

### Lección 3.1.1 — Error en entrenamiento
### Lección 3.1.2 — Error en validación
### Lección 3.1.3 — Patrones típicos

## 3.2 — Curvas de aprendizaje

### Lección 3.2.1 — Qué son
### Lección 3.2.2 — Interpretación
### Lección 3.2.3 — Decisiones a partir de curvas

---

# Unidad 4 — Overfitting: causas habituales

## 4.1 — Complejidad excesiva del modelo

### Lección 4.1.1 — Demasiados parámetros
### Lección 4.1.2 — Modelos muy flexibles
### Lección 4.1.3 — Ajuste al ruido

## 4.2 — Problemas en los datos

### Lección 4.2.1 — Pocos datos
### Lección 4.2.2 — Datos no representativos
### Lección 4.2.3 — Data leakage

---

# Unidad 5 — Underfitting: causas habituales

## 5.1 — Modelos demasiado simples

### Lección 5.1.1 — Falta de capacidad
### Lección 5.1.2 — Relaciones no capturadas
### Lección 5.1.3 — Supuestos incorrectos

## 5.2 — Feature engineering insuficiente

### Lección 5.2.1 — Variables pobres
### Lección 5.2.2 — Información perdida
### Lección 5.2.3 — Representación inadecuada

---

# Unidad 6 — Cómo combatir el overfitting

## 6.1 — Regularización

### Lección 6.1.1 — Penalizar la complejidad
### Lección 6.1.2 — Ridge y Lasso (intuición)
### Lección 6.1.3 — Impacto en generalización

## 6.2 — Otras estrategias

### Lección 6.2.1 — Más datos
### Lección 6.2.2 — Simplificar el modelo
### Lección 6.2.3 — Early stopping

---

# Unidad 7 — Cómo combatir el underfitting

## 7.1 — Aumentar capacidad del modelo

### Lección 7.1.1 — Modelos más complejos
### Lección 7.1.2 — Más parámetros
### Lección 7.1.3 — Nuevas relaciones

## 7.2 — Mejorar los datos

### Lección 7.2.1 — Mejor feature engineering
### Lección 7.2.2 — Variables no lineales
### Lección 7.2.3 — Uso de conocimiento de dominio

---

# Unidad 8 — Overfitting y tipo de modelo

## 8.1 — Modelos lineales

### Lección 8.1.1 — Riesgos típicos
### Lección 8.1.2 — Regularización como clave
### Lección 8.1.3 — Interpretación

## 8.2 — Árboles y ensembles

### Lección 8.2.1 — Profundidad excesiva
### Lección 8.2.2 — Número de árboles
### Lección 8.2.3 — Trade-offs prácticos

---

# Unidad 9 — Overfitting en Deep Learning (visión conceptual)

## 9.1 — Redes neuronales y capacidad

### Lección 9.1.1 — Millones de parámetros
### Lección 9.1.2 — Riesgos de memorizar
### Lección 9.1.3 — Regularización moderna

## 9.2 — Técnicas habituales

### Lección 9.2.1 — Dropout
### Lección 9.2.2 — Data augmentation
### Lección 9.2.3 — Early stopping

---

# Unidad 10 — Evaluación correcta para evitar engaños

## 10.1 — Buenas prácticas de validación

### Lección 10.1.1 — Separación correcta de datos
### Lección 10.1.2 — Validación cruzada
### Lección 10.1.3 — No optimizar sobre test

## 10.2 — Errores frecuentes

### Lección 10.2.1 — Ajustar al test
### Lección 10.2.2 — Comparaciones injustas
### Lección 10.2.3 — Falsa confianza

---

# Unidad 11 — Interpretación y toma de decisiones

## 11.1 — Cuándo aceptar un modelo

### Lección 11.1.1 — Error aceptable
### Lección 11.1.2 — Estabilidad
### Lección 11.1.3 — Robustez

## 11.2 — Comunicar overfitting y underfitting

### Lección 11.2.1 — Explicar a perfiles no técnicos
### Lección 11.2.2 — Mostrar límites
### Lección 11.2.3 — Responsabilidad profesional

---

# Unidad 12 — Mini-proyecto de diagnóstico

## 12.1 — Proyecto guiado

### Lección 12.1.1 — Entrenar varios modelos
### Lección 12.1.2 — Análisis de errores
### Lección 12.1.3 — Curvas de aprendizaje
### Lección 12.1.4 — Corrección de problemas
### Lección 12.1.5 — Conclusiones razonadas

---

# Unidad 13 — Siguientes pasos

## 13.1 — Qué aprender después

### Lección 13.1.1 — Feature engineering avanzado
### Lección 13.1.2 — Evaluación y validación avanzada
### Lección 13.1.3 — Optimización de modelos

## 13.2 — Ruta recomendada en comoprogramar.es

### Lección 13.2.1 — Evaluación y validación de modelos
### Lección 13.2.2 — Feature engineering
### Lección 13.2.3 — Machine Learning clásico

---

## Recursos recomendados

## Glosario (opcional)

## Créditos

> Última actualización: **2025-12-26**

