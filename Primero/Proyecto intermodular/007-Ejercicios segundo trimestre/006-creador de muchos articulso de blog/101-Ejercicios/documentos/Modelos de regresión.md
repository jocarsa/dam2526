---
slug: modelos-de-regresion
title: Modelos de regresión (comoprogramar.es)
description: Aprende a diseñar, entrenar e interpretar modelos de regresión en machine learning. Comprende los principales algoritmos de predicción numérica, sus supuestos, métricas y uso correcto en problemas reales.
keywords:
  - modelos de regresión
  - regresión lineal
  - regresión múltiple
  - regresión regularizada
  - machine learning regresión
  - predicción numérica
level: Intermedio
duration_estimate: "30-45 horas"
prerequisites:
  - "Machine Learning desde cero"
  - "Aprendizaje supervisado"
  - "Probabilidad y estadística para IA"
audience:
  - "Estudiantes de ciencia de datos"
  - "Científicos de datos en formación"
  - "Ingenieros de IA"
  - "Analistas de datos"
updated: 2025-12-26
---

# Modelos de regresión

## Objetivos del curso

## Cómo usar este curso

## Predecir números no es solo ajustar una curva

---

# Unidad 1 — Qué es un problema de regresión

## 1.1 — Predicción de valores continuos

### Lección 1.1.1 — Regresión como estimación
### Lección 1.1.2 — Diferencia entre regresión y clasificación
### Lección 1.1.3 — Casos reales de regresión

## 1.2 — Supuestos básicos en regresión

### Lección 1.2.1 — Relación entre variables
### Lección 1.2.2 — Ruido y variabilidad
### Lección 1.2.3 — Riesgos de extrapolación

---

# Unidad 2 — Regresión lineal simple

## 2.1 — Modelo lineal básico

### Lección 2.1.1 — Recta de regresión
### Lección 2.1.2 — Interpretación geométrica
### Lección 2.1.3 — Coeficientes e intercepto

## 2.2 — Ajuste del modelo

### Lección 2.2.1 — Mínimos cuadrados
### Lección 2.2.2 — Error residual
### Lección 2.2.3 — Limitaciones del modelo lineal simple

---

# Unidad 3 — Regresión lineal múltiple

## 3.1 — Múltiples variables explicativas

### Lección 3.1.1 — Modelo multivariable
### Lección 3.1.2 — Interpretación de coeficientes
### Lección 3.1.3 — Importancia relativa de variables

## 3.2 — Problemas habituales

### Lección 3.2.1 — Multicolinealidad
### Lección 3.2.2 — Variables irrelevantes
### Lección 3.2.3 — Overfitting

---

# Unidad 4 — Evaluación de modelos de regresión

## 4.1 — Métricas fundamentales

### Lección 4.1.1 — MAE
### Lección 4.1.2 — MSE y RMSE
### Lección 4.1.3 — Interpretación práctica de errores

## 4.2 — Coeficiente de determinación

### Lección 4.2.1 — R²
### Lección 4.2.2 — R² ajustado
### Lección 4.2.3 — Errores comunes de interpretación

---

# Unidad 5 — Supuestos del modelo lineal

## 5.1 — Supuestos clásicos

### Lección 5.1.1 — Linealidad
### Lección 5.1.2 — Homocedasticidad
### Lección 5.1.3 — Independencia de errores

## 5.2 — Diagnóstico del modelo

### Lección 5.2.1 — Análisis de residuos
### Lección 5.2.2 — Detección de outliers
### Lección 5.2.3 — Cuándo el modelo no es adecuado

---

# Unidad 6 — Regresión no lineal y transformaciones

## 6.1 — Relaciones no lineales

### Lección 6.1.1 — Curvas y funciones
### Lección 6.1.2 — Transformaciones de variables
### Lección 6.1.3 — Interpretación tras transformar

## 6.2 — Regresión polinómica

### Lección 6.2.1 — Extensión del modelo lineal
### Lección 6.2.2 — Grado del polinomio
### Lección 6.2.3 — Riesgos de sobreajuste

---

# Unidad 7 — Regularización en regresión

## 7.1 — Por qué regularizar

### Lección 7.1.1 — Overfitting en regresión
### Lección 7.1.2 — Bias vs variance
### Lección 7.1.3 — Interpretabilidad

## 7.2 — Métodos de regularización

### Lección 7.2.1 — Ridge
### Lección 7.2.2 — Lasso
### Lección 7.2.3 — Elastic Net

---

# Unidad 8 — Modelos de regresión alternativos

## 8.1 — Regresión basada en árboles

### Lección 8.1.1 — Árboles de regresión
### Lección 8.1.2 — Random Forest para regresión
### Lección 8.1.3 — Gradient Boosting para regresión

## 8.2 — Comparación con modelos lineales

### Lección 8.2.1 — Potencia predictiva
### Lección 8.2.2 — Interpretabilidad
### Lección 8.2.3 — Coste computacional

---

# Unidad 9 — Feature engineering para regresión

## 9.1 — Selección de variables

### Lección 9.1.1 — Variables relevantes
### Lección 9.1.2 — Variables redundantes
### Lección 9.1.3 — Impacto en el modelo

## 9.2 — Escalado y normalización

### Lección 9.2.1 — Por qué escalar
### Lección 9.2.2 — Impacto en regularización
### Lección 9.2.3 — Casos prácticos

---

# Unidad 10 — Interpretación y confianza

## 10.1 — Interpretar predicciones

### Lección 10.1.1 — Intervalos de confianza
### Lección 10.1.2 — Incertidumbre
### Lección 10.1.3 — Límites del modelo

## 10.2 — Riesgos de mal uso

### Lección 10.2.1 — Extrapolación indebida
### Lección 10.2.2 — Decisiones basadas en estimaciones
### Lección 10.2.3 — Responsabilidad profesional

---

# Unidad 11 — Regresión en producción

## 11.1 — Uso real de modelos de regresión

### Lección 11.1.1 — Predicción batch
### Lección 11.1.2 — Predicción en tiempo real
### Lección 11.1.3 — Latencia y costes

## 11.2 — Mantenimiento del modelo

### Lección 11.2.1 — Drift de datos
### Lección 11.2.2 — Reentrenamiento
### Lección 11.2.3 — Monitorización del error

---

# Unidad 12 — Mini-proyecto de regresión

## 12.1 — Proyecto guiado completo

### Lección 12.1.1 — Definición del problema
### Lección 12.1.2 — Exploración y preparación de datos
### Lección 12.1.3 — Entrenamiento de varios modelos
### Lección 12.1.4 — Evaluación comparativa
### Lección 12.1.5 — Selección final y conclusiones

---

# Unidad 13 — Siguientes pasos

## 13.1 — Qué aprender después

### Lección 13.1.1 — Series temporales
### Lección 13.1.2 — Machine Learning avanzado
### Lección 13.1.3 — Deep Learning para regresión

## 13.2 — Ruta recomendada en comoprogramar.es

### Lección 13.2.1 — Modelos de clasificación
### Lección 13.2.2 — Machine Learning clásico
### Lección 13.2.3 — Deep Learning desde cero

---

## Recursos recomendados

## Glosario (opcional)

## Créditos

> Última actualización: **2025-12-26**

