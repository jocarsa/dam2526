---
slug: redes-convolucionales-cnn
title: Redes convolucionales (CNN) (comoprogramar.es)
description: Aprende redes convolucionales (CNN) desde los fundamentos hasta su aplicación práctica en visión por computador. Comprende convoluciones, pooling, arquitecturas y entrenamiento de modelos visuales con Deep Learning.
keywords:
  - redes convolucionales
  - cnn
  - deep learning vision
  - vision artificial
  - convoluciones
  - computer vision deep learning
level: Intermedio–Avanzado
duration_estimate: "40-60 horas"
prerequisites:
  - "Visión por computador desde cero"
  - "Procesamiento digital de imágenes"
  - "Redes neuronales desde cero"
  - "Deep Learning con Python"
audience:
  - "Estudiantes de inteligencia artificial"
  - "Científicos de datos"
  - "Ingenieros de Deep Learning"
updated: 2025-12-26
---

# Redes convolucionales (CNN)

## Objetivos del curso

## Cómo usar este curso

## Enseñar a las redes a ver

---

# Unidad 1 — Por qué las CNN son necesarias

## 1.1 — Límites de redes densas en imágenes

### Lección 1.1.1 — Dimensionalidad de imágenes
### Lección 1.1.2 — Número de parámetros
### Lección 1.1.3 — Pérdida de estructura espacial

## 1.2 — Idea central de las CNN

### Lección 1.2.1 — Convolución como detector de patrones
### Lección 1.2.2 — Compartición de pesos
### Lección 1.2.3 — Invariancia espacial

---

# Unidad 2 — Convolución explicada intuitivamente

## 2.1 — Filtros y kernels

### Lección 2.1.1 — Qué aprende un filtro
### Lección 2.1.2 — Kernels como detectores
### Lección 2.1.3 — Interpretación visual

## 2.2 — Operación de convolución

### Lección 2.2.1 — Desplazamiento del kernel
### Lección 2.2.2 — Suma ponderada
### Lección 2.2.3 — Feature maps

---

# Unidad 3 — Parámetros de la convolución

## 3.1 — Stride, padding y tamaño

### Lección 3.1.1 — Stride y resolución
### Lección 3.1.2 — Padding SAME vs VALID
### Lección 3.1.3 — Cálculo de dimensiones

## 3.2 — Canales y profundidad

### Lección 3.2.1 — Imágenes multicanal
### Lección 3.2.2 — Filtros 3D
### Lección 3.2.3 — Crecimiento de representaciones

---

# Unidad 4 — Funciones de activación y no linealidad

## 4.1 — Activaciones en CNN

### Lección 4.1.1 — ReLU como estándar
### Lección 4.1.2 — Saturación y gradientes
### Lección 4.1.3 — Impacto en aprendizaje

## 4.2 — Activaciones modernas (visión general)

### Lección 4.2.1 — Leaky ReLU
### Lección 4.2.2 — ELU / GELU
### Lección 4.2.3 — Cuándo usarlas

---

# Unidad 5 — Pooling y reducción espacial

## 5.1 — Por qué reducir resolución

### Lección 5.1.1 — Robustez espacial
### Lección 5.1.2 — Reducción de parámetros
### Lección 5.1.3 — Trade-offs

## 5.2 — Tipos de pooling

### Lección 5.2.1 — Max pooling
### Lección 5.2.2 — Average pooling
### Lección 5.2.3 — Global pooling

---

# Unidad 6 — Arquitectura completa de una CNN

## 6.1 — Bloques convolucionales

### Lección 6.1.1 — Conv + ReLU + Pool
### Lección 6.1.2 — Profundización progresiva
### Lección 6.1.3 — Extracción jerárquica de features

## 6.2 — De mapas a decisiones

### Lección 6.2.1 — Flatten
### Lección 6.2.2 — Capas densas finales
### Lección 6.2.3 — Clasificación vs regresión

---

# Unidad 7 — Entrenamiento de CNN

## 7.1 — Preparación de datos visuales

### Lección 7.1.1 — Normalización de imágenes
### Lección 7.1.2 — Tamaños consistentes
### Lección 7.1.3 — Batch de imágenes

## 7.2 — Entrenar correctamente

### Lección 7.2.1 — Función de pérdida
### Lección 7.2.2 — Optimizadores
### Lección 7.2.3 — Curvas de entrenamiento

---

# Unidad 8 — Regularización en CNN

## 8.1 — Overfitting en visión

### Lección 8.1.1 — Pocos datos
### Lección 8.1.2 — Alta capacidad
### Lección 8.1.3 — Señales de sobreajuste

## 8.2 — Técnicas habituales

### Lección 8.2.1 — Data augmentation
### Lección 8.2.2 — Dropout en CNN
### Lección 8.2.3 — Batch Normalization

---

# Unidad 9 — Interpretación de CNN

## 9.1 — Qué aprende cada capa

### Lección 9.1.1 — Bordes y texturas
### Lección 9.1.2 — Partes de objetos
### Lección 9.1.3 — Representaciones abstractas

## 9.2 — Visualización de activaciones

### Lección 9.2.1 — Feature maps
### Lección 9.2.2 — Filtros aprendidos
### Lección 9.2.3 — Interpretabilidad básica

---

# Unidad 10 — CNN modernas (visión general)

## 10.1 — Arquitecturas históricas

### Lección 10.1.1 — LeNet
### Lección 10.1.2 — AlexNet
### Lección 10.1.3 — VGG

## 10.2 — Arquitecturas profundas

### Lección 10.2.1 — ResNet
### Lección 10.2.2 — Inception
### Lección 10.2.3 — EfficientNet

---

# Unidad 11 — Transfer learning en visión

## 11.1 — Uso de modelos preentrenados

### Lección 11.1.1 — Qué es transfer learning
### Lección 11.1.2 — Congelar capas
### Lección 11.1.3 — Fine-tuning

## 11.2 — Cuándo usarlo

### Lección 11.2.1 — Pocos datos
### Lección 11.2.2 — Coste computacional
### Lección 11.2.3 — Riesgos

---

# Unidad 12 — Mini-proyecto con CNN

## 12.1 — Proyecto guiado completo

### Lección 12.1.1 — Definición del problema visual
### Lección 12.1.2 — Preparación del dataset
### Lección 12.1.3 — Construcción de la CNN
### Lección 12.1.4 — Entrenamiento y evaluación
### Lección 12.1.5 — Análisis de resultados

---

# Unidad 13 — Siguientes pasos

## 13.1 — Qué aprender después

### Lección 13.1.1 — Detección de objetos
### Lección 13.1.2 — Segmentación semántica
### Lección 13.1.3 — Visión artificial en producción

## 13.2 — Ruta recomendada en comoprogramar.es

### Lección 13.2.1 — Visión por computador con Deep Learning
### Lección 13.2.2 — Deep Learning con Python
### Lección 13.2.3 — Flujo completo de un proyecto de IA

---

## Recursos recomendados

## Glosario (opcional)

## Créditos

> Última actualización: **2025-12-26**

