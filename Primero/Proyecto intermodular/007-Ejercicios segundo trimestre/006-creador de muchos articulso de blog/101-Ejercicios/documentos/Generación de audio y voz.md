---
slug: generacion-de-audio-y-voz
title: Generación de audio y voz (comoprogramar.es)
description: Aprende a generar audio y voz con IA. Comprende modelos generativos para sonido, música y síntesis de voz (TTS), desde fundamentos acústicos hasta pipelines modernos y aplicaciones reales.
keywords:
  - generacion de audio con ia
  - generacion de voz ia
  - text to speech
  - tts
  - audio generativo
  - ia generativa multimodal
level: Intermedio–Avanzado
duration_estimate: "40-60 horas"
prerequisites:
  - "Introducción a la IA generativa"
  - "Deep Learning con Python"
  - "Procesamiento digital de señales (recomendado)"
audience:
  - "Desarrolladores"
  - "Ingenieros de audio"
  - "Creadores de contenido"
  - "Estudiantes de IA"
updated: 2025-12-26
---

# Generación de audio y voz

## Objetivos del curso

## Cómo usar este curso

## Generar sonido es modelar el tiempo

---

# Unidad 1 — Qué significa generar audio con IA

## 1.1 — Naturaleza del audio

### Lección 1.1.1 — Señales temporales
### Lección 1.1.2 — Frecuencia y amplitud
### Lección 1.1.3 — Percepción humana del sonido

## 1.2 — Casos de uso reales

### Lección 1.2.1 — Síntesis de voz
### Lección 1.2.2 — Música generativa
### Lección 1.2.3 — Efectos sonoros

---

# Unidad 2 — Representación del audio

## 2.1 — Audio como dato numérico

### Lección 2.1.1 — Muestreo
### Lección 2.1.2 — PCM y formatos
### Lección 2.1.3 — Duración y resolución

## 2.2 — Dominio del tiempo y frecuencia

### Lección 2.2.1 — Waveforms
### Lección 2.2.2 — Espectrogramas
### Lección 2.2.3 — Transformada de Fourier

---

# Unidad 3 — Introducción a la síntesis de voz (TTS)

## 3.1 — Qué es TTS

### Lección 3.1.1 — Texto a voz
### Lección 3.1.2 — Naturalidad y prosodia
### Lección 3.1.3 — Retos principales

## 3.2 — Evolución histórica

### Lección 3.2.1 — Síntesis concatenativa
### Lección 3.2.2 — Síntesis paramétrica
### Lección 3.2.3 — Deep Learning y TTS neural

---

# Unidad 4 — Modelos neuronales para audio

## 4.1 — Modelar secuencias largas

### Lección 4.1.1 — Dependencias temporales
### Lección 4.1.2 — Coste computacional
### Lección 4.1.3 — Estabilidad del entrenamiento

## 4.2 — Modelos generativos de audio

### Lección 4.2.1 — Autoencoders para audio
### Lección 4.2.2 — GANs para audio
### Lección 4.2.3 — Diffusion models para audio

---

# Unidad 5 — Texto a voz moderno (TTS neural)

## 5.1 — Pipeline TTS actual

### Lección 5.1.1 — Texto → fonemas
### Lección 5.1.2 — Prosodia y duración
### Lección 5.1.3 — Vocoder neural

## 5.2 — Vocoders

### Lección 5.2.1 — WaveNet (visión conceptual)
### Lección 5.2.2 — WaveGlow
### Lección 5.2.3 — HiFi-GAN

---

# Unidad 6 — Control de la voz generada

## 6.1 — Características vocales

### Lección 6.1.1 — Tono
### Lección 6.1.2 — Velocidad
### Lección 6.1.3 — Entonación

## 6.2 — Clonación de voz (visión técnica)

### Lección 6.2.1 — Speaker embeddings
### Lección 6.2.2 — Adaptación de locutor
### Lección 6.2.3 — Riesgos y límites

---

# Unidad 7 — Generación de música y sonido

## 7.1 — Música como estructura temporal

### Lección 7.1.1 — Ritmo
### Lección 7.1.2 — Armonía
### Lección 7.1.3 — Repetición y variación

## 7.2 — Modelos para música generativa

### Lección 7.2.1 — Modelos simbólicos
### Lección 7.2.2 — Audio directo
### Lección 7.2.3 — Control creativo

---

# Unidad 8 — Calidad y evaluación del audio

## 8.1 — Métricas técnicas

### Lección 8.1.1 — SNR
### Lección 8.1.2 — Distorsión
### Lección 8.1.3 — Artefactos

## 8.2 — Evaluación perceptual

### Lección 8.2.1 — Tests humanos
### Lección 8.2.2 — Naturalidad
### Lección 8.2.3 — Fatiga auditiva

---

# Unidad 9 — Latencia y tiempo real

## 9.1 — Audio en tiempo real

### Lección 9.1.1 — Requisitos de latencia
### Lección 9.1.2 — Streaming de audio
### Lección 9.1.3 — Compromisos calidad–velocidad

## 9.2 — Optimización práctica

### Lección 9.2.1 — Modelos ligeros
### Lección 9.2.2 — Inferencia incremental
### Lección 9.2.3 — Uso en edge devices

---

# Unidad 10 — Riesgos, ética y legalidad

## 10.1 — Riesgos técnicos

### Lección 10.1.1 — Suplantación de identidad
### Lección 10.1.2 — Deepfake de voz
### Lección 10.1.3 — Uso malintencionado

## 10.2 — Uso responsable

### Lección 10.2.1 — Consentimiento
### Lección 10.2.2 — Transparencia
### Lección 10.2.3 — Buenas prácticas

---

# Unidad 11 — Generación de audio en producción

## 11.1 — Integración en sistemas

### Lección 11.1.1 — APIs de TTS
### Lección 11.1.2 — Procesamiento por lotes
### Lección 11.1.3 — Costes operativos

## 11.2 — Gestión de resultados

### Lección 11.2.1 — Almacenamiento
### Lección 11.2.2 — Versionado
### Lección 11.2.3 — Trazabilidad

---

# Unidad 12 — Mini-proyecto de generación de audio

## 12.1 — Proyecto guiado completo

### Lección 12.1.1 — Definición del objetivo sonoro
### Lección 12.1.2 — Preparación de entradas
### Lección 12.1.3 — Generación de audio o voz
### Lección 12.1.4 — Evaluación perceptual
### Lección 12.1.5 — Presentación final

---

# Unidad 13 — Siguientes pasos

## 13.1 — Qué aprender después

### Lección 13.1.1 — ASR (voz a texto)
### Lección 13.1.2 — Sistemas conversacionales multimodales
### Lección 13.1.3 — Generación audiovisual

## 13.2 — Ruta recomendada en comoprogramar.es

### Lección 13.2.1 — Generación de texto con LLMs
### Lección 13.2.2 — Generación de imágenes con IA
### Lección 13.2.3 — Ética y riesgos de la IA

---

## Recursos recomendados

## Glosario (opcional)

## Créditos

> Última actualización: **2025-12-26**

