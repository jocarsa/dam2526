---
slug: etica-y-riesgos-de-la-inteligencia-artificial
title: Ética y riesgos de la Inteligencia Artificial (comoprogramar.es)
description: Analiza los riesgos técnicos, sociales y éticos de la inteligencia artificial. Aprende a identificar sesgos, evaluar impactos, comprender responsabilidades y diseñar sistemas de IA de forma responsable.
keywords:
  - ética de la inteligencia artificial
  - riesgos de la IA
  - sesgos algorítmicos
  - IA responsable
  - explicabilidad
  - regulación de la IA
  - impacto social de la IA
level: Principiante–Intermedio
duration_estimate: "15-25 horas"
prerequisites:
  - "Introducción a la Inteligencia Artificial o conocimientos equivalentes"
audience:
  - "Estudiantes de inteligencia artificial"
  - "Desarrolladores y científicos de datos"
  - "Responsables de producto y decisión"
  - "Profesionales interesados en IA responsable"
updated: 2025-12-26
---

# Ética y riesgos de la Inteligencia Artificial

## Objetivos del curso

## Cómo usar este curso

## Por qué la ética es inseparable de la IA

---

# Unidad 1 — Por qué la IA plantea problemas éticos

## 1.1 — La IA como tecnología de impacto social

### Lección 1.1.1 — Escala y automatización
### Lección 1.1.2 — Decisiones que afectan a personas
### Lección 1.1.3 — Diferencias con software tradicional

## 1.2 — Qué entendemos por “riesgo” en IA

### Lección 1.2.1 — Riesgos técnicos
### Lección 1.2.2 — Riesgos sociales
### Lección 1.2.3 — Riesgos legales y reputacionales

---

# Unidad 2 — Sesgos algorítmicos

## 2.1 — Qué es un sesgo algorítmico

### Lección 2.1.1 — Sesgo en datos
### Lección 2.1.2 — Sesgo en modelos
### Lección 2.1.3 — Sesgo en uso e interpretación

## 2.2 — Origen de los sesgos

### Lección 2.2.1 — Datos históricos
### Lección 2.2.2 — Variables proxy
### Lección 2.2.3 — Decisiones de diseño

## 2.3 — Impacto de los sesgos

### Lección 2.3.1 — Discriminación automatizada
### Lección 2.3.2 — Exclusión y desigualdad
### Lección 2.3.3 — Casos reales documentados

---

# Unidad 3 — Privacidad y protección de datos

## 3.1 — Datos personales y IA

### Lección 3.1.1 — Qué datos usa la IA
### Lección 3.1.2 — Datos sensibles
### Lección 3.1.3 — Inferencias no explícitas

## 3.2 — Riesgos para la privacidad

### Lección 3.2.1 — Reidentificación
### Lección 3.2.2 — Vigilancia automatizada
### Lección 3.2.3 — Uso secundario de datos

## 3.3 — Principios de protección de datos

### Lección 3.3.1 — Minimización
### Lección 3.3.2 — Consentimiento
### Lección 3.3.3 — Limitación de propósito

---

# Unidad 4 — Opacidad y falta de explicabilidad

## 4.1 — El problema de la “caja negra”

### Lección 4.1.1 — Modelos opacos
### Lección 4.1.2 — Dificultad de auditoría
### Lección 4.1.3 — Riesgos en decisiones críticas

## 4.2 — Explicabilidad en IA

### Lección 4.2.1 — Qué significa explicar un modelo
### Lección 4.2.2 — Explicabilidad técnica vs humana
### Lección 4.2.3 — Límites reales de la explicabilidad

---

# Unidad 5 — Errores, fallos y daños

## 5.1 — Fallos inevitables de la IA

### Lección 5.1.1 — Falsos positivos y negativos
### Lección 5.1.2 — Generalización incorrecta
### Lección 5.1.3 — Cambios en el entorno

## 5.2 — Daños causados por sistemas de IA

### Lección 5.2.1 — Decisiones injustas
### Lección 5.2.2 — Daños económicos
### Lección 5.2.3 — Daños psicológicos y sociales

---

# Unidad 6 — IA y toma de decisiones automatizada

## 6.1 — Automatización de decisiones

### Lección 6.1.1 — Ventajas operativas
### Lección 6.1.2 — Riesgos de delegar decisiones
### Lección 6.1.3 — Supervisión humana

## 6.2 — Human-in-the-loop

### Lección 6.2.1 — Qué significa realmente
### Lección 6.2.2 — Cuándo es imprescindible
### Lección 6.2.3 — Falsa supervisión humana

---

# Unidad 7 — IA generativa y nuevos riesgos

## 7.1 — Generación de contenido sintético

### Lección 7.1.1 — Texto, imagen, audio y vídeo
### Lección 7.1.2 — Deepfakes
### Lección 7.1.3 — Desinformación

## 7.2 — Riesgos específicos de modelos generativos

### Lección 7.2.1 — Alucinaciones
### Lección 7.2.2 — Contenido dañino
### Lección 7.2.3 — Uso malintencionado

---

# Unidad 8 — Responsabilidad y rendición de cuentas

## 8.1 — Quién es responsable cuando la IA falla

### Lección 8.1.1 — Desarrolladores
### Lección 8.1.2 — Empresas
### Lección 8.1.3 — Usuarios

## 8.2 — Trazabilidad de sistemas de IA

### Lección 8.2.1 — Datos de entrenamiento
### Lección 8.2.2 — Versionado de modelos
### Lección 8.2.3 — Registro de decisiones

---

# Unidad 9 — Regulación y marcos legales

## 9.1 — Por qué regular la IA

### Lección 9.1.1 — Protección de derechos
### Lección 9.1.2 — Seguridad jurídica
### Lección 9.1.3 — Confianza social

## 9.2 — Enfoques regulatorios actuales

### Lección 9.2.1 — Regulación basada en riesgo
### Lección 9.2.2 — Obligaciones para desarrolladores
### Lección 9.2.3 — Limitaciones de la regulación

---

# Unidad 10 — Principios de IA responsable

## 10.1 — Principios éticos comunes

### Lección 10.1.1 — Justicia
### Lección 10.1.2 — Transparencia
### Lección 10.1.3 — Beneficencia y no maleficencia

## 10.2 — De principios a prácticas

### Lección 10.2.1 — Diseño responsable
### Lección 10.2.2 — Evaluación de impacto
### Lección 10.2.3 — Auditorías internas

---

# Unidad 11 — Pensar éticamente como profesional de IA

## 11.1 — Criterio profesional

### Lección 11.1.1 — Decir “no” a un proyecto
### Lección 11.1.2 — Identificar riesgos ocultos
### Lección 11.1.3 — Responsabilidad individual

## 11.2 — Ética más allá de la ley

### Lección 11.2.1 — Lo legal no siempre es ético
### Lección 11.2.2 — Impacto a largo plazo
### Lección 11.2.3 — Cultura profesional

---

# Unidad 12 — Mini-proyecto de evaluación ética

## 12.1 — Proyecto guiado

### Lección 12.1.1 — Análisis de un sistema de IA real
### Lección 12.1.2 — Identificación de riesgos
### Lección 12.1.3 — Propuesta de mitigación
### Lección 12.1.4 — Evaluación de impacto
### Lección 12.1.5 — Conclusiones razonadas

---

# Unidad 13 — Conclusiones y futuro responsable

## 13.1 — Qué hemos aprendido

### Lección 13.1.1 — Riesgos inevitables
### Lección 13.1.2 — Importancia del criterio
### Lección 13.1.3 — IA como herramienta, no autoridad

## 13.2 — Ruta recomendada en comoprogramar.es

### Lección 13.2.1 — IA responsable y explicable
### Lección 13.2.2 — Machine Learning desde cero
### Lección 13.2.3 — IA aplicada en contextos reales

---

## Recursos recomendados

## Glosario (opcional)

## Créditos

> Última actualización: **2025-12-26**

