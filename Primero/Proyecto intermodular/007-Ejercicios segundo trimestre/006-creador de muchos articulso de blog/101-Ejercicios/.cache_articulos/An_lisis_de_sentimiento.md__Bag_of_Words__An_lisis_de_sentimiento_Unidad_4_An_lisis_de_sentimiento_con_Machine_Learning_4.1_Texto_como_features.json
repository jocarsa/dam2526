{
  "source_file": "Análisis de sentimiento.md",
  "category": "Análisis de sentimiento, Unidad 4 — Análisis de sentimiento con Machine Learning, 4.1 — Texto como features",
  "title": "Bag of Words",
  "generated_at": "2026-01-12 15:45:23",
  "model": "qwen2.5:7b-instruct-q4_0",
  "content": "# Bag of Words: Un método fundamental para análisis de sentimiento\n\n## Introducción\n\nEl **Bag of Words** (BOW) es una técnica básica pero crucial en el procesamiento del lenguaje natural (NLP), especialmente cuando se trata de analizar sentimientos. Esta técnica transforma un texto en una colección de palabras, ignorando la gramática y el orden. En términos sencillos, se tratan las oraciones como \"bolsas\" llenas de palabras sin considerar si estas están juntas o no.\n\n## Explicación principal\n\nEl método BOW se basa en contar cuántas veces aparece cada palabra en un texto, pero sin considerar su orden. Esto se logra creando un diccionario con todas las palabras únicas del corpus de entrenamiento y luego contabilizando la frecuencia de cada palabra en el texto a analizar.\n\n### Ejemplo\n\nConsideremos una frase:\n```python\nfrase = \"Me encanta programar en Python\"\n```\n\nY un diccionario con palabras únicas:\n```python\ndiccionario = set([\"Me\", \"encanta\", \"programar\", \"en\", \"Python\"])\n```\n\nEl BOW resultante sería:\n```plaintext\n{\n    \"Me\": 1,\n    \"encanta\": 1,\n    \"programar\": 1,\n    \"en\": 1,\n    \"Python\": 1\n}\n```\n\n### Transformación en vector\n\nLa **Bag of Words** transforma cada documento en un vector numérico, donde la dimensión del vector corresponde a todas las palabras únicas en el corpus. Cada elemento en el vector representa cuántas veces aparece una palabra en ese texto.\n\nPor ejemplo:\n```python\nfrom sklearn.feature_extraction.text import CountVectorizer\n\n# Crear y entrenar un modelo de BOW\nvectorizador = CountVectorizer()\ncorpus = [\"Me encanta programar en Python\", \"Python es maravilloso para análisis de datos\"]\nmatriz_bow = vectorizador.fit_transform(corpus)\n\nprint(vectorizador.get_feature_names_out())\nprint(matriz_bow.toarray())\n```\n\n### Salida esperada\n```plaintext\n['analisis', 'es', 'programar', 'para', 'python']\n[[0, 0, 1, 0, 1],\n [1, 0, 0, 1, 1]]\n```\n\n## Errores típicos / trampas\n\n### Trampa 1: Ignorar el orden\nLa técnica BOW ignora completamente la secuencia en que aparecen las palabras. Esto puede resultar en perdida de información significativa, especialmente en textos donde el orden es crucial.\n\n### Trampa 2: No capturar contexto\nBOW no considera si una palabra se encuentra cerca de otra o si está precedida por ciertas palabras (contexto). Por ejemplo, \"no programar\" y \"programar\" podrían tener significados opuestos en el contexto.\n\n### Trampa 3: Sensibilidad a la redundancia\nEl BOW puede ser sensible a las repeticiones innecesarias de palabras. Si una frase contiene muchas veces la misma palabra, puede resultar en un vector con valores muy altos para esa palabra, lo que no es necesariamente significativo.\n\n## Checklist accionable\n\n1. **Entendimiento del contexto**: Asegúrate de que el BOW no esté siendo utilizado en situaciones donde el orden y la secuencia sean importantes.\n2. **Preprocesamiento adecuado**: Realiza un preprocesamiento adecuado (tokenización, eliminación de stop words) antes de aplicar BOW.\n3. **Comparación con otros métodos**: Compara los resultados del BOW con técnicas más avanzadas como TF-IDF o embeddings para verificar su efectividad en el caso particular de tu problema.\n4. **Normalización del texto**: Normaliza el texto eliminando simbolos, números y caracteres especiales que no aportan significado al análisis.\n5. **Uso de diccionarios personalizados**: Si existe un vocabulario específico conocido para tu dominio, utiliza un diccionario personalizado en lugar del BOW genérico.\n\n## Cierre\n\n### Siguientes pasos\n\n- **Avanzar a TF-IDF**: TF-IDF (Term Frequency-Inverse Document Frequency) es una mejora sobre el Bag of Words que considera la importancia de las palabras basada en su frecuencia relativa.\n- **Explorar técnicas avanzadas**: Investiga y aplica técnicas más avanzadas como Word2Vec, FastText o BERT para capturar mejor el contexto y el significado de las palabras.\n- **Analizar sentimientos en español**: Considera los desafíos específicos del análisis de sentimientos en español, donde la gramática y el contexto pueden jugar un papel crucial.\n\nEl Bag of Words es una base sólida para comenzar a analizar sentimientos, pero conozca sus limitaciones y tenga preparados otros métodos para obtener resultados más precisos.",
  "hierarchy": {
    "h1": "Unidad 4 — Análisis de sentimiento con Machine Learning",
    "h2": "4.1 — Texto como features",
    "h3_raw": "Lección 4.1.1 — Bag of Words"
  }
}