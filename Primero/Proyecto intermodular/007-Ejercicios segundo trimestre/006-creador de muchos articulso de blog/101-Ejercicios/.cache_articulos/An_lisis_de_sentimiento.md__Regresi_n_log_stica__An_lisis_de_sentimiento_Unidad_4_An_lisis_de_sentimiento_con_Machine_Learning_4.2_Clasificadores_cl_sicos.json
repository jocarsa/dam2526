{
  "source_file": "Análisis de sentimiento.md",
  "category": "Análisis de sentimiento, Unidad 4 — Análisis de sentimiento con Machine Learning, 4.2 — Clasificadores clásicos",
  "title": "Regresión logística",
  "generated_at": "2026-01-12 15:47:12",
  "model": "qwen2.5:7b-instruct-q4_0",
  "content": "# Regresión logística: Clasificación basada en probabilidad\n\n## Introducción\n\nLa regresión logística es una técnica de clasificación que ha sido fundamental en la inteligencia artificial y el análisis de datos durante décadas. Es particularmente útil cuando se trata de predecir si un evento ocurre o no (por ejemplo, si un usuario dará una reseña positiva o negativa). A diferencia de otros algoritmos, la regresión logística ofrece la posibilidad de obtener probabilidades estimadas para cada clase. Esto es especialmente valioso en aplicaciones donde se necesita entender no solo a qué categoría pertenece el dato sino también cuán seguros estamos con esa clasificación.\n\n## Explicación principal\n\nLa regresión logística utiliza una función de logística (también conocida como sigmoidal) para modelar las probabilidades. La ecuación general para la regresión logística se puede expresar así:\n\n\\[\nP(Y = 1 | X; \\theta) = \\frac{1}{1 + e^{-(\\theta_0 + \\theta_1X_1 + ... + \\theta_nX_n)}}\n\\]\n\nDonde:\n- \\(Y\\) es la variable de salida, que puede tomar valores entre 0 y 1.\n- \\(X_i\\) son las características de entrada.\n- \\(\\theta_i\\) son los parámetros del modelo.\n\n### Ejemplo práctico\n\nSupongamos que queremos clasificar reseñas de productos en positivas (1) o negativas (0). Podemos representar esto con el siguiente código:\n\n```python\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\n# Datos ficticios: características (textos procesados) y etiquetas\nX = [\n    \"El producto es excelente\",\n    \"Es malo, no recomendaría\",\n    \"Funciona bien pero el precio es alto\",\n]\ny = [1, 0, 1]  # Positivo, negativo, neutro\n\n# Preprocesamiento (se omite para simplificar)\nX_processed = np.array(X)  # En la práctica, aquí deberían estar las características procesadas\n\n# División de los datos en entrenamiento y prueba\nX_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n\n# Creación del modelo\nmodel = LogisticRegression(max_iter=1000)\nmodel.fit(X_train, y_train)\n\n# Predicciones\ny_pred = model.predict(X_test)\nprint(\"Predicciones:\", y_pred)\n\n# Evaluación de la precisión\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Precisión: {accuracy * 100:.2f}%\")\n```\n\n### Errores típicos / trampas\n\n1. **No linealidad**: La regresión logística asume una relación lineal entre las características y el logaritmo de las probabilidades. Si la relación no es lineal, el modelo puede fallar.\n2. **Multicolinealidad**: Cuando dos o más variables independientes están altamente correlacionadas, puede afectar negativamente al rendimiento del modelo. Es importante identificar e eliminar estas correlaciones antes de entrenar el modelo.\n3. **Problemas con datos imbalancedos**: Si los datos son imbalancedos (por ejemplo, muy pocos casos positivos), la regresión logística puede sesgar su predicción hacia la clase dominante.\n\n## Checklist accionable\n\n### Pasos para implementar una regresión logística efectiva:\n\n1. **Preprocesamiento de datos**: Convertir texto en características numéricas adecuadas, como embeddings o bag of words.\n2. **Selección de características**: Identificar y seleccionar las características más relevantes para la predicción.\n3. **Gestión del balanceo de clases**: Usar técnicas como oversampling, undersampling o SMOTE si los datos están imbalancedos.\n4. **Entrenamiento del modelo**: Ajustar parámetros y realizar validación cruzada para evitar overfitting.\n5. **Evaluación del modelo**: Utilizar métricas adecuadas (accuracy, precision, recall) y graficar la curva ROC-AUC.\n\n### Ejemplos de implementación\n\n1. **Usar embeddings preentrenados**: En lugar de representaciones vectoriales aleatorias, usar embeddings como Word2Vec o BERT puede mejorar significativamente el rendimiento.\n2. **Regularización**: Aplicar L1 (Lasso) o L2 (Ridge) regularización para evitar overfitting y mejor manejo del ruido en los datos.\n\n## Cierre\n\n### Siguientes pasos\n\n- **Aprender más sobre embeddings**: Investigar cómo usar embeddings preentrenados como BERT, Word2Vec, GloVe.\n- **Practicar con conjuntos de datos reales**: Trabajar con datasets públicos o privados para mejorar tus habilidades en la implementación y evaluación del modelo.\n- **Explorar técnicas avanzadas**: Investigar sobre modelos de clasificación más modernos como XGBoost, LightGBM, o utilizar redes neuronales para mejorar el rendimiento.\n\nLa regresión logística es una herramienta valiosa en el análisis de sentimientos. Con su capacidad para proporcionar probabilidades y manejar datos imbalancedos, es una opción sólida para muchos problemas de clasificación. Sin embargo, es importante estar consciente de sus limitaciones y aplicar técnicas adicionales para mejorar la precisión del modelo.",
  "hierarchy": {
    "h1": "Unidad 4 — Análisis de sentimiento con Machine Learning",
    "h2": "4.2 — Clasificadores clásicos",
    "h3_raw": "Lección 4.2.2 — Regresión logística"
  }
}